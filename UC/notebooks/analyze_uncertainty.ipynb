{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KM(ds, target_col):\n",
    "    \n",
    "    total_match = 0\n",
    "    for sample in ds:\n",
    "        corr_ans = sample['ground_truth']\n",
    "\n",
    "        is_corr = 0\n",
    "\n",
    "        for ref in corr_ans:\n",
    "            if ref in sample[target_col]:\n",
    "                is_corr= 1\n",
    "        \n",
    "        total_match += is_corr\n",
    "\n",
    "    return total_match / len(ds)\n",
    "\n",
    "def add_KM(sample, target_col, gt_col):\n",
    "    corr_ans = sample[gt_col]\n",
    "\n",
    "    is_corr = 0\n",
    "\n",
    "    for ref in corr_ans:\n",
    "        if ref in sample[target_col]:\n",
    "            is_corr= 1\n",
    "        \n",
    "    sample[f'KM_{target_col}'] = is_corr\n",
    "    \n",
    "    return sample\n",
    "\n",
    "def add_self_rag_retrieval(sample):\n",
    "    sample['self_rag_need_retrieval'] = '[Retrieval]' in sample['self_rag_response']\n",
    "    return sample\n",
    "\n",
    "def need_context(sample, with_context_col, without_context_col, need_context_col):\n",
    "\n",
    "    if sample[f'KM_{with_context_col}'] > sample[f'KM_{without_context_col}']:\n",
    "        need_context = 1\n",
    "    else:\n",
    "        need_context = 0\n",
    "\n",
    "    sample[need_context_col] = need_context\n",
    "    return sample    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_from_disk('../data/datasets/nq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " 0.6,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.5,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.8,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.8,\n",
       " nan,\n",
       " 0.6,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " 0.6,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.25,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.19999999999999996,\n",
       " 0.6,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.050000000000000044,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.09999999999999998,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.25,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.09999999999999998,\n",
       " 0.5,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.010000000000000009,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " 1.0,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.55,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.8,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " 0.6,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " 0.4,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " 0.4,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " 1.0,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.55,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " 0.8,\n",
       " 0.6,\n",
       " nan,\n",
       " 0.55,\n",
       " 0.25,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.30000000000000004,\n",
       " 0.050000000000000044,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " 0.050000000000000044,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " 0.19999999999999996,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 1.0,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " 0.15000000000000002,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.09999999999999998,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 1.0,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.050000000000000044,\n",
       " 0.4,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.65,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.5,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.050000000000000044,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.4,\n",
       " 0.30000000000000004,\n",
       " 0.6,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " 0.15000000000000002,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.09999999999999998,\n",
       " 0.09999999999999998,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.09999999999999998,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.8,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.4,\n",
       " 1.0,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.6,\n",
       " 0.30000000000000004,\n",
       " 0.15000000000000002,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.55,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.09999999999999998,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " 0.4,\n",
       " nan,\n",
       " nan,\n",
       " 0.4,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.75,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.050000000000000044,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.30000000000000004,\n",
       " 0.8,\n",
       " 0.050000000000000044,\n",
       " 0.30000000000000004,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.8,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " 0.050000000000000044,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.44999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.09999999999999998,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.7,\n",
       " 0.15000000000000002,\n",
       " 0.09999999999999998,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.6,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " 0.15000000000000002,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.09999999999999998,\n",
       " nan,\n",
       " 0.35,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.09999999999999998,\n",
       " 0.6,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.09999999999999998,\n",
       " 0.19999999999999996,\n",
       " 0.95,\n",
       " 0.30000000000000004,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.4,\n",
       " 0.6,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.55,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.25,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.4,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.5,\n",
       " 0.30000000000000004,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 1.0,\n",
       " 0.09999999999999998,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " 0.09999999999999998,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.4,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " 0.4,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.15000000000000002,\n",
       " 0.050000000000000044,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.25,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.65,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.09999999999999998,\n",
       " 0.15000000000000002,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " 0.09999999999999998,\n",
       " 0.6,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.09999999999999998,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.09999999999999998,\n",
       " 0.19999999999999996,\n",
       " 0.050000000000000044,\n",
       " 0.6,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.050000000000000044,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.55,\n",
       " 0.7,\n",
       " 0.55,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " 0.6,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.09999999999999998,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " 0.09999999999999998,\n",
       " nan,\n",
       " nan,\n",
       " 0.55,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.050000000000000044,\n",
       " 0.050000000000000044,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.6,\n",
       " nan,\n",
       " 0.8,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.09999999999999998,\n",
       " nan,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.7,\n",
       " nan,\n",
       " nan,\n",
       " 0.15000000000000002,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.15000000000000002,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.15000000000000002,\n",
       " 0.19999999999999996,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.09999999999999998,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " 0.15000000000000002,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.050000000000000044,\n",
       " 0.6,\n",
       " nan,\n",
       " nan,\n",
       " 0.30000000000000004,\n",
       " nan,\n",
       " 0.19999999999999996,\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['Verbalized1S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(partial(add_KM, target_col='all_context_response', gt_col='ground_truth'))\n",
    "ds = ds.map(partial(add_KM, target_col='no_context_response', gt_col='ground_truth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(partial(add_KM, target_col='all_context_response', gt_col='ground_truth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(partial(need_context, with_context_col='all_context_response', without_context_col='no_context_response',\n",
    "                    need_context_col='gt_need_retrieval'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(ds['gt_need_retrieval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35668549905838043"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'Perplexity': ds['Perplexity'],\n",
    "    'MeanTokenEntropy': ds['MeanTokenEntropy'],\n",
    "    'PTrue': ds['PTrue'],\n",
    "   # 'Verbalized1S': ds['Verbalized1S']\n",
    "})\n",
    "\n",
    "# Assuming y is a 1D numpy array\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating feature: Perplexity\n",
      "Correlation with y: 0.149\n",
      "Accuracy: 0.644\n",
      "ROC AUC: 0.598\n",
      "[[1685   23]\n",
      " [ 921   26]]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Evaluating feature: MeanTokenEntropy\n",
      "Correlation with y: 0.182\n",
      "Accuracy: 0.639\n",
      "ROC AUC: 0.623\n",
      "[[1614   94]\n",
      " [ 864   83]]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Evaluating feature: PTrue\n",
      "Correlation with y: 0.003\n",
      "Accuracy: 0.643\n",
      "ROC AUC: 0.493\n",
      "[[1708    0]\n",
      " [ 947    0]]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    print(f\"Evaluating feature: {col}\")\n",
    "\n",
    "    # Step 1: Correlation\n",
    "    corr, _ = pearsonr(data[col], y)\n",
    "    print(f\"Correlation with y: {corr:.3f}\")\n",
    "    \n",
    "    # Step 2: Logistic regression to predict y from the single feature\n",
    "    X = data[[col]].values  # Use only the current feature\n",
    "    \n",
    "    # Initialize the logistic regression model\n",
    "    log_reg = LogisticRegression()\n",
    "    \n",
    "    # Fit the logistic regression model\n",
    "    log_reg.fit(X, y)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = log_reg.predict(X)\n",
    "    y_pred_prob = log_reg.predict_proba(X)[:, 1]  # For ROC AUC\n",
    "    \n",
    "    # Step 3: Evaluate accuracy and ROC AUC\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    roc_auc = roc_auc_score(y, y_pred_prob)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "    \n",
    "    # Step 4: Draw confusion matrix\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "    print(conf_matrix)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "    # disp.plot()\n",
    "   # plt.title(f\"Confusion Matrix for {col}\")\n",
    "   # plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.608\n",
      "ROC AUC: 0.625\n"
     ]
    }
   ],
   "source": [
    "X = data.values  # Features matrix\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# Fit the logistic regression model\n",
    "log_reg.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_reg.predict(X)\n",
    "y_pred_prob = log_reg.predict_proba(X)[:, 1]  # For ROC AUC\n",
    "\n",
    "# Step 3: Evaluate accuracy, ROC AUC\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "roc_auc = roc_auc_score(y, y_pred_prob)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2655"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating feature: Perplexity\n",
      "Best threshold on train set for Perplexity: 0.156 with ROC AUC: 0.592\n",
      "ROC AUC on validation set for Perplexity: 0.580\n",
      "==================================================\n",
      "Evaluating feature: MeanTokenEntropy\n",
      "Best threshold on train set for MeanTokenEntropy: 0.311 with ROC AUC: 0.587\n",
      "ROC AUC on validation set for MeanTokenEntropy: 0.597\n",
      "==================================================\n",
      "Evaluating feature: PTrue\n",
      "Best threshold on train set for PTrue: 35.717 with ROC AUC: 0.503\n",
      "ROC AUC on validation set for PTrue: 0.500\n",
      "==================================================\n",
      "Summary of results:\n",
      "Feature: Perplexity\n",
      "  Best Threshold: 0.156\n",
      "  Train ROC AUC: 0.592\n",
      "  Validation ROC AUC: 0.580\n",
      "==================================================\n",
      "Feature: MeanTokenEntropy\n",
      "  Best Threshold: 0.311\n",
      "  Train ROC AUC: 0.587\n",
      "  Validation ROC AUC: 0.597\n",
      "==================================================\n",
      "Feature: PTrue\n",
      "  Best Threshold: 35.717\n",
      "  Train ROC AUC: 0.503\n",
      "  Validation ROC AUC: 0.500\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "num_train = 600\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, y, train_size=num_train, stratify=y, random_state=42)\n",
    "\n",
    "# Function to find the best threshold that maximizes ROC AUC\n",
    "def find_best_threshold(column, y_train):\n",
    "    best_threshold = 0\n",
    "    best_roc_auc = 0\n",
    "    thresholds = np.linspace(column.min(), column.max(), 100)\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # Predicting based on threshold\n",
    "        y_pred_train = (column >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate ROC AUC for this threshold\n",
    "        roc_auc = roc_auc_score(y_train, y_pred_train)\n",
    "        \n",
    "        # Update the best threshold if this is better\n",
    "        if roc_auc > best_roc_auc:\n",
    "            best_roc_auc = roc_auc\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_roc_auc\n",
    "\n",
    "# Step 2: For each feature, find the threshold that maximizes ROC AUC on training set\n",
    "results = {}\n",
    "\n",
    "for col in X_train.columns:\n",
    "    print(f\"Evaluating feature: {col}\")\n",
    "    \n",
    "    # Find the best threshold for this feature on the training set\n",
    "    best_threshold, best_roc_auc_train = find_best_threshold(X_train[col], y_train)\n",
    "    print(f\"Best threshold on train set for {col}: {best_threshold:.3f} with ROC AUC: {best_roc_auc_train:.3f}\")\n",
    "    \n",
    "    # Step 3: Evaluate on the validation set using the found threshold\n",
    "    y_pred_val = (X_val[col] >= best_threshold).astype(int)\n",
    "    roc_auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "    print(f\"ROC AUC on validation set for {col}: {roc_auc_val:.3f}\")\n",
    "    \n",
    "    # Store results\n",
    "    results[col] = {\n",
    "        'best_threshold': best_threshold,\n",
    "        'train_roc_auc': best_roc_auc_train,\n",
    "        'validation_roc_auc': roc_auc_val\n",
    "    }\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Displaying the summary of results for each feature\n",
    "print(\"Summary of results:\")\n",
    "for col, metrics in results.items():\n",
    "    print(f\"Feature: {col}\")\n",
    "    print(f\"  Best Threshold: {metrics['best_threshold']:.3f}\")\n",
    "    print(f\"  Train ROC AUC: {metrics['train_roc_auc']:.3f}\")\n",
    "    print(f\"  Validation ROC AUC: {metrics['validation_roc_auc']:.3f}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
